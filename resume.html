<!-- Resume of Alex Bahouth -->
<html>
  <head>
    <link rel="stylesheet" type="text/css" href="resume.css" />
  </head>
  <body>
    <div id="Header">
      <div id="Name">Alex Bahouth</div>
      <div id="ContactInfo">
        <a href="http://www.linkedin.com/pub/alex-bahouth/6/7a0/229"
           style="text-decoration:none;">
          <span style="font: 80% Arial,sans-serif; color:#0783B6;">
            Contact Me
            <img src="http://www.linkedin.com/img/webpromo/btn_in_20x15.png"
                 width="20" height="15" alt="Contact Me Via LinkedIn"
                 style="vertical-align:middle" border="0" />
          </span>
        </a>
      </div>
    </div>
    <div id="Education" class="section">
      <div class="section-heading">Education</div>
      <div class="section-body">
        B.S. Computer Science, University of California, Davis 2002 - 2006
      </div>
    </div>
    <br />
    <div id="WorkExperience" class="section">
      <div class="section-heading">Professional Experience</div>
      <div class="section-body">
        <div class="job-descriptions">
		  <div id="OKL" class="job-description">
            <div class="workplace-heading">
              <br/>
              <div id="LeftCenterRight" class="workplace-heading">
                <div id="Left">One Kings Lane, Sand Francisco, CA</div>
                <div id="Right">Nov 2012 - Current</div>
              </div>
            </div>
            <br/>
            <div id="LeftCenterRight" class="workplace-heading">
			  <div id="Left">Director of Data Engineering</div>
			  <div id="Right">Clojure, Ruby, Vertica, Amazon Web Services
			  </div>
            </div>
            <br/>
			<li>
				Architect of the Data Warehouse and Data Platform tools
				<ul>
				  <li>
					Carried out the technology evaluation, selection, and launch of our Vertica Data Warehouse
				  </li>
				  <li>
					Managed consultants and embedded members the team to				work directly with consultants to ensure rapid and successful launch as well as knowledge transfer
				  </li>
				  <li>
					Expanding the 4 node Vertica cluster to 16 nodes to keep up with business demand
				  </li>
				  <li>
					Enabled interactive querying of our events and email data streams, which in the realm of hundreds of millions to billions of rows.
				  </li>
				  <li>
					Delivered a platform that allowed for business-changing analysis to be carried out that could not have been carried out before that pivoted the business mission and goals for second half of 2014 into 2015.
				  </li>
				</ul>
			</li> <!-- end Architect of DW -->
			<li>
			  Driving the dissemination of data throughout the organization
			  <ul>
				<li>
				  Consult the business on data-based initiatives to ensure sanity checking and cross collaboration. Often called in to manage projects that have lost their focus or coordination across business partners.
				</li>
				<li>
				  Consult the business on ever evolving data needs and scaling the data platform to meet the needs of more and more teams.
				</li>
				<li>
				  Driving the adoption of Looker to enable faster data insight iteration and integration
				</li>
				<li>
				  Collaborate with analytic partners all across the business to continue to provide direction for the data platform to meet business needs.
				</li>
			  </ul>
			</li> <!-- end of Architect -->
			<li>Built the Data Engineering Team
			  <ul>
				<li>Built a team from 0 to 10 engineers</li>
				<li>Built our process, constantly evolving process as code</li>
				<li> Defined the on call responsibilities </li>
				<li> Built a robust platform and service team from solid generalists </li>
				<li> Developed our internal customer support flow </li>
				<li> Re-engaged the organization to reopen the dialogue with engineering </li>
				<li>Constantly performing self reflection with the team, and balancing addressing internal development with the need to drive business value</li>
				<li>Set up a team able to run 4-5 projects in parallel, delegating to tech leads for execution</li>
				<li> Foster a positive, merit based culture, with clear expectations and definitions </li>
				<li> Constantly working to prevent myself from being a single point of failure for the team as a manager</li>
				<li> Embed team members within projects to ensure they drive to completion and maintain commitments.</li>
				<li> Rebuilt communication channels and reset the bar for organizational engagement with Engineering </li>
				<li> Wrote the Engineering Career Path for the engineering organization <a href="https://github.com/okl/engineering-careers/blob/master/engineering-progression.md">https://github.com/okl/engineering-careers/blob/master/engineering-progression.md</a>
			  </ul>
			</li> <!-- end of Built Danger -->
			<li>Created, Designed, Spec’d, or evolved a number of solutions for managing data flows in and out of the data warehouse
			  <ul>
				<li>
				  Created and guided continued development of type system heavily inspired by Apache Avro to handle semi-structured and structured schema representation, extraction, analysis, and resolution. <a href="https://github.com/okl/danger-jsonschema">https://github.com/okl/danger-jsonschema</a> (Don’t let the name fool you, it’s not only JSON)
				</li>
				<li>
				  Created a generic Clojure DSL framework used in many applications to rapidly develop DSLs and ensure that practiced separation of concerns are made simple. <a href="https://github.com/okl/danger-diesel">https://github.com/okl/danger-diesel</a>
				</li>
				<li> Designed and built the prototypal implementation of our JSON processing framework, enabling the definition of data transformation to be independently bound to Unix pipe streams, Hadoop, Storm or other data processing frameworks. <a href="https://github.com/okl/danger-jawsome">https://github.com/okl/danger-jawsome </a> (and an additional private repo)
				</li>
				<li> Implemented a small library to efficiently project arbitrarily nested JSON data into formats easily loadable into a tabular database. <a href="https://github.com/okl/danger-denormal">https://github.com/okl/danger-denormal</a>
				</li>
				<li> Guided the design of a DSL for data monitoring that could be bootstrapped as a live quality checking service, as well as generate iChinga rules for data monitors and data alerting, sharing the same logic. <a href="https://github.com/okl/danger-data-watch-dog">https://github.com/okl/danger-data-watch-dog</a>
				</li>
				<li> Built our event stream data processing pipeline with Clojure (compiled to native Java) on top of Amazon Elastic Map-Reduce (EMR); contributing enhancements to <a href="https://github.com/alexott/clojure-hadoop">https://github.com/alexott/clojure-hadoop</a>
				</li>
				<li> Designed Beastload our internal Database-to-Database data replication utility that can automatically manage data based replication as well as cross database schema changes (soon to be open sourced)
				</li>
			  </ul>
			</li> <!--end of Created -->
		  </div> <!-- End OKL -->
		  <br/>
          <div id="Merced" class="job-description">
            <div class="workplace-heading">
              <br/>
              <div id="LeftCenterRight" class="workplace-heading">
                <div id="Left">Merced Systems, Redwood Shores, CA</div>
                <div id="Right">(Acq. by NICE Systems 2/2012)</div>
              </div>
			</div>
            <br/>
            <div id="LeftCenterRight" class="workplace-heading">
			  <div id="Left">Senior Software Engineer</div>
			  <div id="Right">July 2007 - July 2012</div>
            </div>
            <br/><br/>
            <div id="LeftCenterRight" class="sub-heading">
			  <div id="Left">(Jan 2012 - July 2012)</div>
			  <div id="Right">
                Java, Hadoop, Avro, Clojure,
                Web<sup><a href="#def1">1</a></sup>
			  </div>
            </div>
            <ul>
			  <li>
				Integrating open source (Hadoop, Avro) with
				proprietary
				technologies (Datameer, SnapLogic) to create a new Big Data
				product line.
			  </li>
			  <li>
                Rebuilt SQL-based solution on top of Hadoop, Avro, and
                Oozie reducing data processing time from 2 hours to a few minutes.
			  <li>
				Playing a consulting role on the future evolution and
                maintenance of Merced's OLAP<sup><a href="#def3">3</a></sup> engine.
			  </li>
            </ul>
			<br/>
			<br/>
			<div id="LeftCenterRight" class="sub-heading">
			  <div id="Left"> (Jul 2007 - Jan 2012)</div>
			  <div id="Right">
				J2EE, Scheme<sup><a href="#def2">2</a></sup>, Web<sup><a href="#def1">1</a></sup>
			  </div>
			</div>
			<ul>
			  <li>
				Company Guru of OLAP Engine
			  </li>
			  <li>
				Redesigned and re-implemented the entire analytic engine                             stack from the database to the reporting layer, with an eye toward calculation expressiveness, scalability and performance.
				<ul>
				  <li>
					Achieved consistent 2x-4x speed improvements regardless of engine usage patterns, and 16-70x speed improvements in common, problematic patterns.
				  </li>
				  <li>
					Achieved triple the amount of concurrency a single application server was able to provide to clients of the analytics engine.
				  </li>
				  <li>
					Designed and implemented additional expressiveness within the analytics engine allowing users to specify more control over their flow of their data through their analysis.
				  </li>
				  <li>
					Integrated the new analytics engine into the existing reporting infrastructure in place, as well as laid the ground work for the necessary services required for a new reporting infrastructure to be built on top.
				  </li>
				  <li>
					Designed and implemented a web-based debugging and tooling to enable users to trace individual data through the temporal and hierarchical transformations from the database through analytics engine to the reporting layer; examine generated queries interactively; and enable calculation correctness due diligence to be carried out.
				  </li>
				</ul>
			  </li>
			  <li>
				Wrote 150 page book on how Merced’s
				analytics engine works at a very concrete conceptual
				level to further promote adoption and general
				understanding by both external and internal customers.
			  </li>
			  <li>
				Implemented features to provide cross-functional integration and drilling between OLAP and OLTP systems.
			  </li>
			  <li>
				Lead project teams for various OLAP-related projects.
			  </li>
			  <li>
				Supported both the Client Services and Customer
				Support teams in Reporting and Analytic design reviews,
				troubleshooting, best practice development, and general
				education with
				respect to the customer uses of the reporting and analytics engines.
			  </li>
			</ul>
		  </div><!-- End Merced 1 -->
          <br/>
          <br/>
          <br/>
          <div id="TSRTP" class="job-description">
			<div id="LeftCenterRight" class="workplace-heading">
              <div id="Left">
				UC Toxic Substances Program, Davis, CA
              </div>
              <div id="Right">April 2004 - July 2009</div>
			</div>
			<br />
			<div id="LeftCenterRight" class="workplace-heading">
              <div id="Left">Software Programmer (II)</div>
              <div id="Right">
				PHP, Python, FileMaker, Web<sup><a href="#def1">1</a></sup>
              </div>
			</div>
			<br/>
			<ul>
              <li>
				Developed web application to heavily automate the grant application, review, awarding, and reporting processes.
              </li>
              <li>
				Automated system maintanence and backup tasks with Unix utilities and Python
              </li>
              <li>
				Administrator of file, web, back up, and subversion servers; provided OSX desktop and server support.
              </li>
			</ul>
			<br/>
          </div> <!-- End TSRTP -->
          <div id="LLNL" class="job-description">
			<br/>
			<div id="LeftCenterRight" class="workplace-heading">
              <div id="Left">Lawrence Livermore National Lab, Livermore, CA</div>
              <div id="Right">Summer 2006</div>
			</div>
			<br/>
			<div id="LeftCenterRight" class="workplace-heading">
              <div id="Left">Undergraduate Researcher</div>
              <div id="Right">Python, C</div>
			</div>
			<br/>


			<ul>
              <li>
				Re-implemented the event management queuing system in SimPy<sup><a href="#def4">4</a></sup> using SWIG to use data structures implemented in C to achieve greater performance throughput and simulation scalability.
              </li>
              <li>
				Research paper was accepted to the 40th Annual Simulation Symposium<sup><a href="#def5">5</a></sup>
              </li>
			</ul>
			<br/>
          </div> <!-- End LLNL -->
		</div> <!-- End Job Descriptions -->
      </div> <!-- End section-body Professional Exerience -->
	</div> <!-- End Work Experience -->
	<br/>
	<div id="Skills" class="section">
	  <div class="section-heading">
		Practiced Skills<sup><a href="#def6">6</a></sup>
	  </div>
	  <div class="section-body">
		<ul>
		  <li>
			<div class="skill-type">
			  Languages<sup><a href="#def7">7</a></sup>:
			</div>
			Clojure, Java, Scheme, Javascript, Python, Ruby, PHP, HTML, CSS, SQL
		  </li>
		  <li>
			<div class="skill-type">Frameworks and Packages:</div>
			Kawa, Hadoop, Avro, REST, Storm, XMLBeans, XML/XSD, YUI2, JSP, Oozie, Jetty, Datameer, SnapLogic
		  </li>
		  <li>
			<div class="skill-type">Development Tools:</div>
			Vagrant,
			Ansible,
			Emacs,
			Git,
			Leiningen,
			VisualVM,
			JClassLib,
			Eclipse,
			Perforce,
			Subversion,
			Maven,
			Mac OSX,
			Ubuntu Linux,
			JProfiler,
			YourKit
		  </li>
		</ul>
	  </div>
	</div> <!-- End Skills -->
	<br/>
	<div id="Activities and Interests" class="section">
	  <div class="section-heading">Activities and Interests</div>
	  <div class="section-body">
		<a href="https://www.youtube.com/watch?v=jYnXmbJgvx4">Fire Dancer </a> studying at <a href="http://templeofpoi.wordpress.com/">Temple of Poi</a> (I'm the one in the front),
		avid group fitness fan,
		Meetup goer, camper, hiker and traveler.
	  </div>
	</div> <!-- End Activities and Interests -->
	<br/>
	<div  id="Footnotes" class="section">
	  <ol>
		<li>
		  <a name="def1">
			AJAX/CSS/Javascript/HTML/JSON and Apache or Apache Tomcat
		  </a>
		</li>
		<li>
		  <a name="def2">
			Merced uses Kawa Scheme
			(<a href="http://www.gnu.org/software/kawa/">http://www.gnu.org/software/kawa/</a>)
			to reap the benefits of a functional language that is
			fully interoperable with standard Java, and able to be
			compiled to java bytecode at both compile-time and run-time.
		  </a>
		</li>
		<li>
		  <a name="def3">
			OLAP is part of the broader category of business
			intelligence, which also encompasses relational reporting
			and data mining
			(<a href="http://en.wikipedia.org/wiki/Online_analytical_processing">http://en.wikipedia.org/wiki/Online_analytical_processing</a>)
		  </a>
		</li>
		<li>
		  <a name="def4">
			SimPy is a simulation package for Python (<a href="http://simpy.readthedocs.org/en/latest/">http://simpy.readthedocs.org/en/latest/</a>)
		</li>
		<li>
		  <a name="def5">
			Available from IEEE <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=4127209">  http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=4127209</a>
		</li>
		<li>
		  <a name="def6">
			The languages, packages, and tools listed below are not
			merely items I have seen and/or tinkered with- but have
			actually used in some meaningful way to develop solutions 			to problems.
		  </a>
		</li>
		<li>
		  <a name="def7">
			While I do have varying levels of experience with C and
			C++, Objective C, Perl, R, and Scala that I can share, I have yet to build anything substantial with them.
		  </a>
		</li>
	  </ol>
	</div> <!-- End Footnotes -->
  </body>
</html>
